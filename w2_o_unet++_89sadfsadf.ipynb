{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T13:07:32.475066Z",
     "iopub.status.busy": "2023-03-04T13:07:32.474549Z",
     "iopub.status.idle": "2023-03-04T13:07:34.810129Z",
     "shell.execute_reply": "2023-03-04T13:07:34.809471Z",
     "shell.execute_reply.started": "2023-03-04T13:07:32.474983Z"
    },
    "ExecuteTime": {
     "start_time": "2023-05-08T21:18:29.060428Z",
     "end_time": "2023-05-08T21:18:33.604485Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from mydataset import MyDataset\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast\n",
    "from data_augmentation import RandomRotation, RandomVerticalFlip, RandomHorizontalFlip, Compose, ToTensor\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T13:07:34.811661Z",
     "iopub.status.busy": "2023-03-04T13:07:34.811451Z",
     "iopub.status.idle": "2023-03-04T13:07:34.814358Z",
     "shell.execute_reply": "2023-03-04T13:07:34.813919Z",
     "shell.execute_reply.started": "2023-03-04T13:07:34.811645Z"
    },
    "ExecuteTime": {
     "start_time": "2023-05-08T21:18:33.607486Z",
     "end_time": "2023-05-08T21:18:33.620486Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "lr = 0.0001\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T13:07:34.815358Z",
     "iopub.status.busy": "2023-03-04T13:07:34.815039Z",
     "iopub.status.idle": "2023-03-04T13:07:34.835364Z",
     "shell.execute_reply": "2023-03-04T13:07:34.834910Z",
     "shell.execute_reply.started": "2023-03-04T13:07:34.815341Z"
    },
    "ExecuteTime": {
     "start_time": "2023-05-08T21:18:33.624488Z",
     "end_time": "2023-05-08T21:18:33.682487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(3800, 200, 1900, 100)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = MyDataset(root=\"data\", is_train=True, transform=Compose([\n",
    "    ToTensor(),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomVerticalFlip(),\n",
    "    RandomRotation([0, 90, 180, 270]),\n",
    "]), normalize=transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)))\n",
    "\n",
    "val_set = MyDataset(root=\"data\", is_train=False, transform=Compose([ToTensor()]),\n",
    "                    normalize=transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "len(train_set), len(val_set), len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T13:07:34.836312Z",
     "iopub.status.busy": "2023-03-04T13:07:34.835994Z",
     "iopub.status.idle": "2023-03-04T13:07:37.786811Z",
     "shell.execute_reply": "2023-03-04T13:07:37.785817Z",
     "shell.execute_reply.started": "2023-03-04T13:07:34.836295Z"
    },
    "ExecuteTime": {
     "start_time": "2023-05-08T21:18:33.671485Z",
     "end_time": "2023-05-08T21:18:34.354555Z"
    }
   },
   "outputs": [],
   "source": [
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=6,\n",
    "    classes=2,\n",
    ")\n",
    "model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optim, mode='max', factor=0.1, patience=2,\n",
    "    verbose=True)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T13:07:37.788063Z",
     "iopub.status.busy": "2023-03-04T13:07:37.787847Z",
     "iopub.status.idle": "2023-03-04T13:07:37.793866Z",
     "shell.execute_reply": "2023-03-04T13:07:37.793163Z",
     "shell.execute_reply.started": "2023-03-04T13:07:37.788045Z"
    },
    "ExecuteTime": {
     "start_time": "2023-05-08T21:18:34.358554Z",
     "end_time": "2023-05-08T21:18:34.370553Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(epoch):\n",
    "    model.train()\n",
    "    print(f\"Epoch {epoch} Training\")\n",
    "    with tqdm(train_loader, desc=str(epoch)) as it:\n",
    "        for idx, (img1, img2, mask) in enumerate(it, 0):\n",
    "            img1, img2, mask = img1.cuda(), img2.cuda(), mask.cuda()\n",
    "            optim.zero_grad()\n",
    "            mask = mask.long()\n",
    "            with autocast():\n",
    "                img = torch.cat((img1, img2), 1)\n",
    "                outputs = model(img)\n",
    "                mask = mask.squeeze(1)\n",
    "                loss = criterion(outputs, mask)\n",
    "            # loss.backward()\n",
    "            # optim.step()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optim)\n",
    "            scaler.update()\n",
    "            #print(outputs.data.shape)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            #print(pred.shape)\n",
    "            p, r, f1, iou = get_index(pred, mask)\n",
    "            it.set_postfix_str(f\"loss: {loss.item(): .4f} p: {p: .4f}  r: {r: .4f}  f1: {f1: .4f}  iou: {iou: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T13:07:37.794671Z",
     "iopub.status.busy": "2023-03-04T13:07:37.794513Z",
     "iopub.status.idle": "2023-03-04T13:07:37.801160Z",
     "shell.execute_reply": "2023-03-04T13:07:37.800539Z",
     "shell.execute_reply.started": "2023-03-04T13:07:37.794655Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-08T21:18:34.378570Z",
     "end_time": "2023-05-08T21:18:34.391558Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_index(pred, label):\n",
    "    eps = 1e-7\n",
    "    tp = torch.sum(label * pred)\n",
    "    fp = torch.sum(pred) - tp\n",
    "    fn = torch.sum(label) - tp\n",
    "\n",
    "    p = (tp + eps) / (tp + fp + eps)\n",
    "    r = (tp + eps) / (tp + fn + eps)\n",
    "    f1 = (2 * p * r + eps) / (p + r + eps)\n",
    "    iou = (tp + eps) / (tp + fn + fp + eps)\n",
    "    return p, r, f1, iou\n",
    "\n",
    "\n",
    "def test_model(epoch):\n",
    "    model.eval()\n",
    "    global max_score\n",
    "    f1s = 0\n",
    "    print(f\"Epoch {epoch} Testing\")\n",
    "    with torch.no_grad():\n",
    "        with tqdm(val_loader, desc=str(epoch)) as it:\n",
    "            for img1, img2, mask in it:\n",
    "                img1, img2, mask = img1.cuda(), img2.cuda(), mask.cuda()\n",
    "                img = torch.cat((img1, img2), 1)\n",
    "                outputs = model(img)\n",
    "                _, pred = torch.max(outputs.data, 1)\n",
    "                mask = mask.squeeze(1)\n",
    "                p, r, f1, iou = get_index(pred, mask)\n",
    "                f1s += f1\n",
    "                it.set_postfix_str(f\"p: {p: .4f}  r: {r: .4f}  f1: {f1: .4f}  iou: {iou: .4f}\")\n",
    "    f1s /= len(val_loader)\n",
    "    scheduler.step(f1s)\n",
    "    print(\"f1\", f1s.item())\n",
    "    if max_score < f1s:\n",
    "        max_score = f1s\n",
    "        print('max_score', max_score.item())\n",
    "    print(type(max_score))\n",
    "    print(type(max_score.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T13:07:37.802997Z",
     "iopub.status.busy": "2023-03-04T13:07:37.802502Z",
     "iopub.status.idle": "2023-03-04T13:19:40.007342Z",
     "shell.execute_reply": "2023-03-04T13:19:40.006740Z",
     "shell.execute_reply.started": "2023-03-04T13:07:37.802980Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0:  15%|█▌        | 289/1900 [00:54<05:03,  5.30it/s, loss:  0.4259 p:  0.9378  r:  0.4648  f1:  0.6216  iou:  0.4509]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m max_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, num_epoch):\n\u001B[1;32m----> 4\u001B[0m     \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     test_model(epoch\u001B[38;5;241m=\u001B[39mepoch)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompleted!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[5], line 17\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(epoch)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# loss.backward()\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# optim.step()\u001B[39;00m\n\u001B[0;32m     16\u001B[0m scaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 17\u001B[0m \u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m scaler\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m#print(outputs.data.shape)\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:341\u001B[0m, in \u001B[0;36mGradScaler.step\u001B[1;34m(self, optimizer, *args, **kwargs)\u001B[0m\n\u001B[0;32m    337\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munscale_(optimizer)\n\u001B[0;32m    339\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo inf checks were recorded for this optimizer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 341\u001B[0m retval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_opt_step(optimizer, optimizer_state, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    343\u001B[0m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstage\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m OptState\u001B[38;5;241m.\u001B[39mSTEPPED\n\u001B[0;32m    345\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:288\u001B[0m, in \u001B[0;36mGradScaler._maybe_opt_step\u001B[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001B[0m\n\u001B[0;32m    286\u001B[0m retval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28msum\u001B[39m(v\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[1;32m--> 288\u001B[0m     retval \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mstep(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001B[0m, in \u001B[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    138\u001B[0m profile_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizer.step#\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.step\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(profile_name):\n\u001B[1;32m--> 140\u001B[0m     out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    141\u001B[0m     obj\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[1;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\optim\\adamw.py:162\u001B[0m, in \u001B[0;36mAdamW.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    158\u001B[0m             max_exp_avg_sqs\u001B[38;5;241m.\u001B[39mappend(state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_exp_avg_sq\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m    160\u001B[0m         state_steps\u001B[38;5;241m.\u001B[39mappend(state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m--> 162\u001B[0m     \u001B[43madamw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    163\u001B[0m \u001B[43m          \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[43m          \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    165\u001B[0m \u001B[43m          \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    166\u001B[0m \u001B[43m          \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    167\u001B[0m \u001B[43m          \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[43m          \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    169\u001B[0m \u001B[43m          \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    170\u001B[0m \u001B[43m          \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    171\u001B[0m \u001B[43m          \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[43m          \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    173\u001B[0m \u001B[43m          \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    174\u001B[0m \u001B[43m          \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[43m          \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    176\u001B[0m \u001B[43m          \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\optim\\adamw.py:219\u001B[0m, in \u001B[0;36madamw\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    217\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adamw\n\u001B[1;32m--> 219\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    220\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    221\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    222\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    223\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    224\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    225\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    226\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    227\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    228\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    229\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    230\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\optim\\adamw.py:273\u001B[0m, in \u001B[0;36m_single_tensor_adamw\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001B[0m\n\u001B[0;32m    270\u001B[0m param\u001B[38;5;241m.\u001B[39mmul_(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m lr \u001B[38;5;241m*\u001B[39m weight_decay)\n\u001B[0;32m    272\u001B[0m \u001B[38;5;66;03m# Decay the first and second moment running average coefficient\u001B[39;00m\n\u001B[1;32m--> 273\u001B[0m \u001B[43mexp_avg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmul_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39madd_(grad, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta1)\n\u001B[0;32m    274\u001B[0m exp_avg_sq\u001B[38;5;241m.\u001B[39mmul_(beta2)\u001B[38;5;241m.\u001B[39maddcmul_(grad, grad, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta2)\n\u001B[0;32m    276\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m capturable:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "max_score = 0\n",
    "for epoch in range(0, num_epoch):\n",
    "    train_model(epoch=epoch)\n",
    "    test_model(epoch=epoch)\n",
    "print(\"completed!\")\n",
    "print('max_score', max_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
