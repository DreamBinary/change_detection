{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T12:16:37.075292Z",
     "iopub.status.busy": "2023-03-08T12:16:37.075045Z",
     "iopub.status.idle": "2023-03-08T12:16:44.469387Z",
     "shell.execute_reply": "2023-03-08T12:16:44.468353Z",
     "shell.execute_reply.started": "2023-03-08T12:16:37.075231Z"
    },
    "ExecuteTime": {
     "start_time": "2023-04-02T20:52:53.588063Z",
     "end_time": "2023-04-02T20:52:53.598053Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install segmentation_models_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T12:16:44.472120Z",
     "iopub.status.busy": "2023-03-08T12:16:44.471775Z",
     "iopub.status.idle": "2023-03-08T12:16:46.703653Z",
     "shell.execute_reply": "2023-03-08T12:16:46.703000Z",
     "shell.execute_reply.started": "2023-03-08T12:16:44.472081Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-04-02T20:52:53.598053Z",
     "end_time": "2023-04-02T20:52:57.944038Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from mydataset2 import MyDataset\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast\n",
    "import segmentation_models_pytorch as smp\n",
    "from data_augmentation import RandomRotation, RandomVerticalFlip, RandomHorizontalFlip, Compose, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T12:16:46.704682Z",
     "iopub.status.busy": "2023-03-08T12:16:46.704473Z",
     "iopub.status.idle": "2023-03-08T12:16:46.707889Z",
     "shell.execute_reply": "2023-03-08T12:16:46.707475Z",
     "shell.execute_reply.started": "2023-03-08T12:16:46.704662Z"
    },
    "ExecuteTime": {
     "start_time": "2023-04-02T20:52:57.944038Z",
     "end_time": "2023-04-02T20:52:57.954019Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T12:16:46.708827Z",
     "iopub.status.busy": "2023-03-08T12:16:46.708672Z",
     "iopub.status.idle": "2023-03-08T12:16:46.733425Z",
     "shell.execute_reply": "2023-03-08T12:16:46.733060Z",
     "shell.execute_reply.started": "2023-03-08T12:16:46.708813Z"
    },
    "ExecuteTime": {
     "start_time": "2023-04-02T20:52:57.974049Z",
     "end_time": "2023-04-02T20:52:58.024019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(3800, 200, 3800, 200)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = MyDataset(root=\"data\", is_train=True, transform=Compose([\n",
    "    ToTensor(),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomVerticalFlip(),\n",
    "    RandomRotation([0, 90, 180, 270]),\n",
    "]), normalize=transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)))\n",
    "\n",
    "val_set = MyDataset(root=\"data\", is_train=False, transform=Compose([ToTensor()]),\n",
    "                    normalize=transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "len(train_set), len(val_set), len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T12:16:46.734148Z",
     "iopub.status.busy": "2023-03-08T12:16:46.733994Z",
     "iopub.status.idle": "2023-03-08T12:16:49.619618Z",
     "shell.execute_reply": "2023-03-08T12:16:49.618879Z",
     "shell.execute_reply.started": "2023-03-08T12:16:46.734133Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-04-02T20:52:58.004029Z",
     "end_time": "2023-04-02T20:52:58.623742Z"
    }
   },
   "outputs": [],
   "source": [
    "model0 = smp.FPN(\n",
    "    in_channels=6,\n",
    "    classes=2,\n",
    ")\n",
    "model0.cuda()\n",
    "criterion0 = nn.CrossEntropyLoss()\n",
    "optim0 = torch.optim.AdamW(model0.parameters(), lr=0.0001, weight_decay=1e-9)\n",
    "scaler0 = torch.cuda.amp.GradScaler(enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T12:16:49.620720Z",
     "iopub.status.busy": "2023-03-08T12:16:49.620554Z",
     "iopub.status.idle": "2023-03-08T12:16:50.004681Z",
     "shell.execute_reply": "2023-03-08T12:16:50.004045Z",
     "shell.execute_reply.started": "2023-03-08T12:16:49.620704Z"
    },
    "ExecuteTime": {
     "start_time": "2023-04-02T20:52:58.623742Z",
     "end_time": "2023-04-02T20:52:59.111588Z"
    }
   },
   "outputs": [],
   "source": [
    "model1 = smp.DeepLabV3Plus(\n",
    "    in_channels=6,\n",
    "    classes=2,\n",
    ")\n",
    "model1.cuda()\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "optim1 = torch.optim.AdamW(model1.parameters(), lr=0.0001, weight_decay=1e-9)\n",
    "scaler1 = torch.cuda.amp.GradScaler(enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T12:16:50.006454Z",
     "iopub.status.busy": "2023-03-08T12:16:50.006279Z",
     "iopub.status.idle": "2023-03-08T12:16:50.405517Z",
     "shell.execute_reply": "2023-03-08T12:16:50.404870Z",
     "shell.execute_reply.started": "2023-03-08T12:16:50.006430Z"
    },
    "ExecuteTime": {
     "start_time": "2023-04-02T20:52:59.111588Z",
     "end_time": "2023-04-02T20:52:59.613648Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = smp.UnetPlusPlus(\n",
    "    in_channels=6,\n",
    "    classes=2,\n",
    ")\n",
    "model2.cuda()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optim2 = torch.optim.AdamW(model2.parameters(), lr=0.0001, weight_decay=1e-9)\n",
    "scaler2 = torch.cuda.amp.GradScaler(enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T12:16:50.406479Z",
     "iopub.status.busy": "2023-03-08T12:16:50.406299Z",
     "iopub.status.idle": "2023-03-08T12:16:50.409759Z",
     "shell.execute_reply": "2023-03-08T12:16:50.409322Z",
     "shell.execute_reply.started": "2023-03-08T12:16:50.406462Z"
    },
    "ExecuteTime": {
     "start_time": "2023-04-02T20:52:59.613648Z",
     "end_time": "2023-04-02T20:52:59.623644Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [model0, model1, model2]\n",
    "criterions = [criterion0, criterion1, criterion2]\n",
    "scalers = [scaler0, scaler1, scaler2]\n",
    "optims = [optim0, optim1, optim2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T12:16:50.410486Z",
     "iopub.status.busy": "2023-03-08T12:16:50.410330Z",
     "iopub.status.idle": "2023-03-08T12:16:50.416763Z",
     "shell.execute_reply": "2023-03-08T12:16:50.416349Z",
     "shell.execute_reply.started": "2023-03-08T12:16:50.410472Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-04-02T20:52:59.623644Z",
     "end_time": "2023-04-02T20:52:59.633646Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(epoch):\n",
    "    for model in models:\n",
    "        model.train()\n",
    "    print(f\"Epoch {epoch} Training\")\n",
    "    with tqdm(train_loader, desc=str(epoch)) as it:\n",
    "        for idx, (img, mask) in enumerate(it, 0):\n",
    "            img, mask = img.cuda(), mask.cuda()\n",
    "            mask = mask.long()\n",
    "            mask = mask.squeeze(1)\n",
    "            vote = []\n",
    "            for model, optim, criterion, scaler in zip(models, optims, criterions, scalers):\n",
    "                optim.zero_grad()\n",
    "                with autocast():\n",
    "                    outputs = model(img)\n",
    "                    loss = criterion(outputs, mask)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optim)\n",
    "                scaler.update()\n",
    "                _, pred = torch.max(outputs.data, 1)\n",
    "                vote.append(pred)\n",
    "            vote = torch.stack(vote, dim=0)\n",
    "            pred = torch.div(torch.sum(vote, dim=0), 2, rounding_mode=\"trunc\")\n",
    "            p, r, f1, iou = get_index(pred, mask)\n",
    "            it.set_postfix_str(f\"loss: {loss.item(): .4f} p: {p: .4f}  r: {r: .4f}  f1: {f1: .4f}  iou: {iou: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T12:16:50.417473Z",
     "iopub.status.busy": "2023-03-08T12:16:50.417318Z",
     "iopub.status.idle": "2023-03-08T12:16:50.423747Z",
     "shell.execute_reply": "2023-03-08T12:16:50.423333Z",
     "shell.execute_reply.started": "2023-03-08T12:16:50.417458Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-04-02T20:52:59.645567Z",
     "end_time": "2023-04-02T20:52:59.675605Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_index(pred, label):\n",
    "    eps = 1e-7\n",
    "    tp = torch.sum(label * pred)\n",
    "    fp = torch.sum(pred) - tp\n",
    "    fn = torch.sum(label) - tp\n",
    "\n",
    "    p = (tp + eps) / (tp + fp + eps)\n",
    "    r = (tp + eps) / (tp + fn + eps)\n",
    "    f1 = (2 * p * r + eps) / (p + r + eps)\n",
    "    iou = (tp + eps) / (tp + fn + fp + eps)\n",
    "    return p, r, f1, iou\n",
    "\n",
    "\n",
    "def test_model(epoch):\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    global max_score\n",
    "    f1s = 0\n",
    "    print(f\"Epoch {epoch} Testing\")\n",
    "    with torch.no_grad():\n",
    "        with tqdm(val_loader, desc=str(epoch)) as it:\n",
    "            for img, mask in it:\n",
    "                img, mask = img.cuda(), mask.cuda()\n",
    "                mask = mask.squeeze(1)\n",
    "                vote = []\n",
    "                for model in models:\n",
    "                    outputs = model(img)\n",
    "                    _, pred = torch.max(outputs.data, 1)\n",
    "                    vote.append(pred)\n",
    "                vote = torch.stack(vote, dim=0)\n",
    "                pred = torch.div(torch.sum(vote, dim=0), 2, rounding_mode=\"trunc\")\n",
    "                p, r, f1, iou = get_index(pred, mask)\n",
    "                f1s += f1\n",
    "                it.set_postfix_str(f\"p: {p: .4f}  r: {r: .4f}  f1: {f1: .4f}  iou: {iou: .4f}\")\n",
    "    f1s /= len(val_loader)\n",
    "    print(\"f1\", f1s.item())\n",
    "    if max_score < f1s:\n",
    "        max_score = f1s\n",
    "        print('max_score', max_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T12:16:50.424454Z",
     "iopub.status.busy": "2023-03-08T12:16:50.424300Z",
     "iopub.status.idle": "2023-03-08T12:33:40.213917Z",
     "shell.execute_reply": "2023-03-08T12:33:40.212961Z",
     "shell.execute_reply.started": "2023-03-08T12:16:50.424439Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0:   0%|          | 0/3800 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m max_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, num_epoch):\n\u001B[1;32m----> 4\u001B[0m     \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     test_model(epoch\u001B[38;5;241m=\u001B[39mepoch)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompleted!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[9], line 14\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(epoch)\u001B[0m\n\u001B[0;32m     12\u001B[0m optim\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast():\n\u001B[1;32m---> 14\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, mask)\n\u001B[0;32m     16\u001B[0m scaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\segmentation_models_pytorch\\base\\model.py:30\u001B[0m, in \u001B[0;36mSegmentationModel.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_input_shape(x)\n\u001B[0;32m     29\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(x)\n\u001B[1;32m---> 30\u001B[0m decoder_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m masks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msegmentation_head(decoder_output)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassification_head \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\segmentation_models_pytorch\\decoders\\deeplabv3\\decoder.py:99\u001B[0m, in \u001B[0;36mDeepLabV3PlusDecoder.forward\u001B[1;34m(self, *features)\u001B[0m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mfeatures):\n\u001B[1;32m---> 99\u001B[0m     aspp_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maspp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    100\u001B[0m     aspp_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mup(aspp_features)\n\u001B[0;32m    101\u001B[0m     high_res_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblock1(features[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m4\u001B[39m])\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\segmentation_models_pytorch\\decoders\\deeplabv3\\decoder.py:187\u001B[0m, in \u001B[0;36mASPP.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    185\u001B[0m res \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m conv \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvs:\n\u001B[1;32m--> 187\u001B[0m     res\u001B[38;5;241m.\u001B[39mappend(\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    188\u001B[0m res \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(res, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproject(res)\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\segmentation_models_pytorch\\decoders\\deeplabv3\\decoder.py:151\u001B[0m, in \u001B[0;36mASPPPooling.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    149\u001B[0m size \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:]\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mod \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 151\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mmod\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39minterpolate(x, size\u001B[38;5;241m=\u001B[39msize, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbilinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, align_corners\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    164\u001B[0m     bn_training \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_mean \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    166\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001B[39;00m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001B[39;00m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001B[39;00m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m--> 171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    173\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001B[39;49;00m\n\u001B[0;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_mean\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\n\u001B[0;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    177\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbn_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexponential_average_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    183\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\nn\\functional.py:2448\u001B[0m, in \u001B[0;36mbatch_norm\u001B[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[0m\n\u001B[0;32m   2435\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m   2436\u001B[0m         batch_norm,\n\u001B[0;32m   2437\u001B[0m         (\u001B[38;5;28minput\u001B[39m, running_mean, running_var, weight, bias),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2445\u001B[0m         eps\u001B[38;5;241m=\u001B[39meps,\n\u001B[0;32m   2446\u001B[0m     )\n\u001B[0;32m   2447\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m training:\n\u001B[1;32m-> 2448\u001B[0m     \u001B[43m_verify_batch_size\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2450\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mbatch_norm(\n\u001B[0;32m   2451\u001B[0m     \u001B[38;5;28minput\u001B[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001B[38;5;241m.\u001B[39mbackends\u001B[38;5;241m.\u001B[39mcudnn\u001B[38;5;241m.\u001B[39menabled\n\u001B[0;32m   2452\u001B[0m )\n",
      "File \u001B[1;32mD:\\Mysoftware_setup\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\nn\\functional.py:2416\u001B[0m, in \u001B[0;36m_verify_batch_size\u001B[1;34m(size)\u001B[0m\n\u001B[0;32m   2414\u001B[0m     size_prods \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m size[i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m   2415\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_prods \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m-> 2416\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected more than 1 value per channel when training, got input size \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(size))\n",
      "\u001B[1;31mValueError\u001B[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])"
     ]
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "max_score = 0\n",
    "for epoch in range(0, num_epoch):\n",
    "    train_model(epoch=epoch)\n",
    "    test_model(epoch=epoch)\n",
    "print(\"completed!\")\n",
    "print('max_score', max_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
